{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bc9d38c-e82d-49f7-bf2c-74757573ebdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/anaconda3/lib/python3.13/site-packages (2.3.0)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.13/site-packages (2.3.2)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.13/site-packages (4.67.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.13/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.13/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /opt/anaconda3/lib/python3.13/site-packages (from openai) (0.11.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/anaconda3/lib/python3.13/site-packages (from openai) (2.10.3)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.13/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/lib/python3.13/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.13/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# å®‰è£…å¿…è¦çš„åº“ (å¦‚æœå·²å®‰è£…å¯è·³è¿‡)\n",
    "#!pip install openai pandas tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ecf52cf-7c4d-4e77-94a8-7779f4687917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åº“å¯¼å…¥æˆåŠŸï¼ŒAPI å®¢æˆ·ç«¯å·²å°±ç»ªï¼\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm # è¿™æ˜¯ä¸€ä¸ªè¿›åº¦æ¡å·¥å…·ï¼Œå¾ˆæ–¹ä¾¿æŸ¥çœ‹è¿›åº¦\n",
    "\n",
    "# è®¾ç½®ä½ çš„ API Key\n",
    "# å»ºè®®ç›´æ¥æŠŠ Key ç²˜è´´åœ¨è¿™é‡Œï¼Œæˆ–è€…ä»ç¯å¢ƒå˜é‡è¯»å–\n",
    "# å¦‚æœä½¿ç”¨çš„æ˜¯ DeepSeek æˆ–å…¶ä»–å…¼å®¹ OpenAI æ ¼å¼çš„æ¨¡å‹ï¼Œä¹Ÿå¯ä»¥åœ¨è¿™é‡Œæ”¹ base_url\n",
    "api_key = \"sk-...\"  # ğŸ”´ è¯·åœ¨è¿™é‡Œæ›¿æ¢ä½ çš„ OpenAI API Key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "print(\"åº“å¯¼å…¥æˆåŠŸï¼ŒAPI å®¢æˆ·ç«¯å·²å°±ç»ªï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "535f2157-e422-4206-a25f-4d5a5393d941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cambridge æ•°æ®é›†æ€»è¡Œæ•°: 331\n",
      "å½“å‰å‡†å¤‡å¤„ç†çš„è¡Œæ•°: 3\n",
      "é¢„è§ˆæ•°æ®:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cefr_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New books this month\\n\\nThe Long Night\\nThis i...</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BURGLARS LOVE THE AFTERNOON\\n\\nMost house burg...</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Madame Tussaud's\\n\\nOne very famous place for ...</td>\n",
       "      <td>A2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text cefr_level\n",
       "0  New books this month\\n\\nThe Long Night\\nThis i...         A2\n",
       "1  BURGLARS LOVE THE AFTERNOON\\n\\nMost house burg...         A2\n",
       "2  Madame Tussaud's\\n\\nOne very famous place for ...         A2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# è¯»å–æ•°æ®\n",
    "df_cambridge = pd.read_csv('cleaned_cambridge.csv')\n",
    "\n",
    "# ğŸ”´ å…³é”®è®¾ç½®ï¼š\n",
    "# æµ‹è¯•æ¨¡å¼ï¼šåªå–å‰ 3 æ¡ï¼ŒéªŒè¯ä»£ç èƒ½å¦è·‘é€šï¼Œé˜²æ­¢æµªè´¹é’±æˆ–æŠ¥é”™\n",
    "# è¿™é‡Œçš„ .head(3) æ„å‘³ç€åªå¤„ç†å‰ 3 è¡Œã€‚\n",
    "# å¦‚æœæµ‹è¯•æˆåŠŸï¼Œä½ éœ€è¦æŠŠ .head(3) åˆ æ‰ï¼Œæ”¹æˆ df_cambridge.copy() æ¥è·‘å…¨é‡\n",
    "test_data = df_cambridge.head(3).copy() \n",
    "\n",
    "print(f\"Cambridge æ•°æ®é›†æ€»è¡Œæ•°: {len(df_cambridge)}\")\n",
    "print(f\"å½“å‰å‡†å¤‡å¤„ç†çš„è¡Œæ•°: {len(test_data)}\")\n",
    "print(\"é¢„è§ˆæ•°æ®:\")\n",
    "display(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b54c4e-a002-4e37-b27b-0c26b265d135",
   "metadata": {},
   "source": [
    "ç”Ÿæˆ A1-C1 å¤šéš¾åº¦å¹³è¡Œè¯­æ–™ (Cambridgeç‰ˆ)\n",
    "Deepseek API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "517a9a00-6d26-473f-890c-291f169b5391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ start mission: 331 lines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 204/331 [2:44:03<3:49:08, 108.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Unterminated string starting at: line 107 column 40 (char 17027)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 208/331 [2:50:14<3:24:55, 99.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Unterminated string starting at: line 6 column 9 (char 12731)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹           | 230/331 [3:15:33<2:42:59, 96.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Unterminated string starting at: line 6 column 9 (char 15740)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 234/331 [3:21:15<2:43:00, 100.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Unterminated string starting at: line 10 column 9 (char 19209)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ         | 249/331 [3:52:16<5:09:54, 226.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 10 column 1 (char 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 250/331 [4:02:18<7:37:51, 339.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 10 column 1 (char 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–        | 252/331 [4:05:50<4:54:25, 223.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Unterminated string starting at: line 6 column 9 (char 16115)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 292/331 [5:02:13<1:15:05, 115.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Unterminated string starting at: line 6 column 9 (char 13673)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 304/331 [5:16:15<39:28, 87.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Unterminated string starting at: line 6 column 9 (char 16503)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 331/331 [5:42:20<00:00, 62.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… mission accomplishedï¼\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_id</th>\n",
       "      <th>original_text</th>\n",
       "      <th>original_cefr</th>\n",
       "      <th>text_A1</th>\n",
       "      <th>text_A2</th>\n",
       "      <th>text_B1</th>\n",
       "      <th>text_B2</th>\n",
       "      <th>text_C1</th>\n",
       "      <th>text_C2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>New books this month\\n\\nThe Long Night\\nThis i...</td>\n",
       "      <td>A2</td>\n",
       "      <td>New books this month. The Long Night: This is ...</td>\n",
       "      <td>New books this month\\n\\nThe Long Night\\nThis i...</td>\n",
       "      <td>New books this month. The Long Night: This is ...</td>\n",
       "      <td>New books this month. The Long Night: This is ...</td>\n",
       "      <td>New books this month. The Long Night: Marking ...</td>\n",
       "      <td>New books this month. The Long Night: This rep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>BURGLARS LOVE THE AFTERNOON\\n\\nMost house burg...</td>\n",
       "      <td>A2</td>\n",
       "      <td>Burglars like the afternoon. Police say most h...</td>\n",
       "      <td>BURGLARS LOVE THE AFTERNOON\\n\\nMost house burg...</td>\n",
       "      <td>Burglars prefer the afternoon. According to th...</td>\n",
       "      <td>Burglars favor the afternoon hours. Police rep...</td>\n",
       "      <td>Burglars exhibit a predilection for the aftern...</td>\n",
       "      <td>Burglars demonstrate a pronounced affinity for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Madame Tussaud's\\n\\nOne very famous place for ...</td>\n",
       "      <td>A2</td>\n",
       "      <td>Madame Tussaud's is a famous place in London. ...</td>\n",
       "      <td>Madame Tussaud's\\n\\nOne very famous place for ...</td>\n",
       "      <td>Madame Tussaud's is a well-known tourist attra...</td>\n",
       "      <td>Madame Tussaud's museum is a prominent tourist...</td>\n",
       "      <td>Madame Tussaud's museum stands as an iconic at...</td>\n",
       "      <td>Madame Tussaud's museum epitomizes a quintesse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Memo \\n\\nTo: All staff \\nSubject: Holidays\\nFr...</td>\n",
       "      <td>A2</td>\n",
       "      <td>Memo to all staff. Subject: Holidays. From: D ...</td>\n",
       "      <td>Memo \\n\\nTo: All staff \\nSubject: Holidays\\nFr...</td>\n",
       "      <td>Memo to all staff. Subject: Holidays. From: D ...</td>\n",
       "      <td>Memo to all staff. Subject: Holidays. From: D ...</td>\n",
       "      <td>Memo to all staff. Subject: Holidays. From: D ...</td>\n",
       "      <td>Memo to all staff. Subject: Holidays. From: D ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CANADA GEESE\\n\\nCanada Geese are large blue an...</td>\n",
       "      <td>A2</td>\n",
       "      <td>Canada Geese are big birds. They are blue and ...</td>\n",
       "      <td>CANADA GEESE\\n\\nCanada Geese are large blue an...</td>\n",
       "      <td>Canada Geese are large birds with blue and whi...</td>\n",
       "      <td>Canada Geese are sizable birds characterized b...</td>\n",
       "      <td>Canada Geese, distinguished by their substanti...</td>\n",
       "      <td>Canada Geese, notable for their considerable s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_id                                      original_text  \\\n",
       "0            0  New books this month\\n\\nThe Long Night\\nThis i...   \n",
       "1            1  BURGLARS LOVE THE AFTERNOON\\n\\nMost house burg...   \n",
       "2            2  Madame Tussaud's\\n\\nOne very famous place for ...   \n",
       "3            3  Memo \\n\\nTo: All staff \\nSubject: Holidays\\nFr...   \n",
       "4            4  CANADA GEESE\\n\\nCanada Geese are large blue an...   \n",
       "\n",
       "  original_cefr                                            text_A1  \\\n",
       "0            A2  New books this month. The Long Night: This is ...   \n",
       "1            A2  Burglars like the afternoon. Police say most h...   \n",
       "2            A2  Madame Tussaud's is a famous place in London. ...   \n",
       "3            A2  Memo to all staff. Subject: Holidays. From: D ...   \n",
       "4            A2  Canada Geese are big birds. They are blue and ...   \n",
       "\n",
       "                                             text_A2  \\\n",
       "0  New books this month\\n\\nThe Long Night\\nThis i...   \n",
       "1  BURGLARS LOVE THE AFTERNOON\\n\\nMost house burg...   \n",
       "2  Madame Tussaud's\\n\\nOne very famous place for ...   \n",
       "3  Memo \\n\\nTo: All staff \\nSubject: Holidays\\nFr...   \n",
       "4  CANADA GEESE\\n\\nCanada Geese are large blue an...   \n",
       "\n",
       "                                             text_B1  \\\n",
       "0  New books this month. The Long Night: This is ...   \n",
       "1  Burglars prefer the afternoon. According to th...   \n",
       "2  Madame Tussaud's is a well-known tourist attra...   \n",
       "3  Memo to all staff. Subject: Holidays. From: D ...   \n",
       "4  Canada Geese are large birds with blue and whi...   \n",
       "\n",
       "                                             text_B2  \\\n",
       "0  New books this month. The Long Night: This is ...   \n",
       "1  Burglars favor the afternoon hours. Police rep...   \n",
       "2  Madame Tussaud's museum is a prominent tourist...   \n",
       "3  Memo to all staff. Subject: Holidays. From: D ...   \n",
       "4  Canada Geese are sizable birds characterized b...   \n",
       "\n",
       "                                             text_C1  \\\n",
       "0  New books this month. The Long Night: Marking ...   \n",
       "1  Burglars exhibit a predilection for the aftern...   \n",
       "2  Madame Tussaud's museum stands as an iconic at...   \n",
       "3  Memo to all staff. Subject: Holidays. From: D ...   \n",
       "4  Canada Geese, distinguished by their substanti...   \n",
       "\n",
       "                                             text_C2  \n",
       "0  New books this month. The Long Night: This rep...  \n",
       "1  Burglars demonstrate a pronounced affinity for...  \n",
       "2  Madame Tussaud's museum epitomizes a quintesse...  \n",
       "3  Memo to all staff. Subject: Holidays. From: D ...  \n",
       "4  Canada Geese, notable for their considerable s...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Using deepseek\n",
    "API_KEY = \"sk-cd3c66b5a2db4f0386ab67b52e6e3196\"  # DeepSeek Key\n",
    "client = OpenAI(api_key=API_KEY, base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "# define all levels\n",
    "ALL_LEVELS = [\"A1\", \"A2\", \"B1\", \"B2\", \"C1\", \"C2\"]\n",
    "\n",
    "# core function\n",
    "def generate_cefr_versions(original_text, original_level):\n",
    "    \"\"\"\n",
    "    input: original text\n",
    "    generate all other levels of text\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Target Levels: if the goal level=original level, than skip the transform\n",
    "    if original_level in ALL_LEVELS:\n",
    "        target_levels = [lvl for lvl in ALL_LEVELS if lvl != original_level]\n",
    "    else:\n",
    "        target_levels = ALL_LEVELS\n",
    "\n",
    "    target_str = \", \".join(target_levels)\n",
    "\n",
    "    # 2. Prompt\n",
    "    system_prompt = f\"\"\"\n",
    "    You are an expert in CEFR-graded English text simplification.\n",
    "    Your task is to rewrite the provided text into these specific levels: {target_str}.\n",
    "    \n",
    "    Strict Constraints:\n",
    "    1. Keep ALL facts, entities, and meaning IDENTICAL to the original.\n",
    "    2. Output PURE JSON format with keys: {json.dumps(target_levels)}.\n",
    "    3. Do NOT generate the level \"{original_level}\" because the user already has it.\n",
    "    4. For lower levels, use simple syntax/vocab. For higher levels, use complex syntax/vocab.\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"Original Text ({original_level}):\\n{original_text}\\n\\nRewrite into JSON format for: {target_str}.\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"deepseek-chat\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            response_format={ \"type\": \"json_object\" },\n",
    "            temperature=0.3\n",
    "        )\n",
    "        content = response.choices[0].message.content\n",
    "        result_dict = json.loads(content)\n",
    "        \n",
    "        # 3. put the original content back to dictionary\n",
    "        if original_level in ALL_LEVELS:\n",
    "            result_dict[original_level] = original_text\n",
    "            \n",
    "        return result_dict\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# main procedure\n",
    "df_cambridge = pd.read_csv('cleaned_cambridge.csv')\n",
    "\n",
    "#  .copy()\n",
    "test_data = df_cambridge.copy() \n",
    "# test_data = df_cambridge.copy() \n",
    "\n",
    "print(f\"ğŸš€ start mission: {len(test_data)} lines\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for index, row in tqdm(test_data.iterrows(), total=test_data.shape[0]):\n",
    "    original_text = row['text']\n",
    "    original_level = row['cefr_level']\n",
    "    \n",
    "    # original_level\n",
    "    versions = generate_cefr_versions(original_text, original_level)\n",
    "    \n",
    "    if versions:\n",
    "        result_entry = {\n",
    "            \"original_id\": index,\n",
    "            \"original_text\": original_text,\n",
    "            \"original_cefr\": original_level,\n",
    "            \"text_A1\": versions.get(\"A1\"),\n",
    "            \"text_A2\": versions.get(\"A2\"),\n",
    "            \"text_B1\": versions.get(\"B1\"),\n",
    "            \"text_B2\": versions.get(\"B2\"),\n",
    "            \"text_C1\": versions.get(\"C1\"),\n",
    "            \"text_C2\": versions.get(\"C2\")\n",
    "        }\n",
    "        results.append(result_entry)\n",
    "\n",
    "df_processed = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\nâœ… mission accomplishedï¼\")\n",
    "display(df_processed.head())\n",
    "\n",
    "df_processed.to_csv(\"cambridge_deepseek_augmented_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ecac56-a705-4521-8d96-54b4bf13103d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1943fe95-89d1-4874-b590-0e5f976f2208",
   "metadata": {},
   "source": [
    "# clear those above original level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61eacacf-1db0-43b1-889d-f254543edd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleanning now...\n",
      "âœ… mission accomplishedï¼\n",
      "original row: 322\n",
      "new row: 322\n",
      "save as: cambridge_simplified levels_only.csv\n",
      "\n",
      " preview level B2 (A1, A2, B1):\n",
      "    original_cefr                                                                                                                                                                                                                                                                                                                           text_A1                                                                                                                                                                                                                                                                                                                                                                                                                                                 text_A2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  text_B1 text_B2 text_C1\n",
      "124            B2  This is about the Watkins family. The father makes musical instruments. The two sons are musicians. Paul plays the cello. Huw plays the piano and writes music. The father made a cello for Paul. Paul used it for many years. Now Paul has a new cello. Both sons are successful. The parents are happy and support their sons.  The Watkins family is very musical. John, the father, makes violins and cellos. He started making instruments because buying one was too expensive. His sons, Paul and Huw, are musicians. Paul is a cellist who won awards and played in an orchestra. Huw is a pianist and composer. The parents encouraged them but did not push them. Paul now uses a new cello, but his father's cello was very good. Both sons have important music events soon.  The Watkins family is unique because John, the father, creates instruments, while his sons, Paul and Huw, are accomplished musicians. John began making cellos after finding commercial options too costly, learning through evening classes. Paul used his father's cello for years, achieving success like winning the BBC Young Musician competition and becoming principal cellist. Now, he uses an older cello on loan. Huw, inspired by his brother, is building a career as a pianist and composer. Their parents supported them without pressure. Soon, both sons have significant performances, making it busy for the family.    None    None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_file = \"cambridge_deepseek_augmented_test.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "\n",
    "cefr_levels = [\"A1\", \"A2\", \"B1\", \"B2\", \"C1\", \"C2\"]\n",
    "level_map = {lvl: i for i, lvl in enumerate(cefr_levels)}\n",
    "\n",
    "def filter_simplification(row):\n",
    "    \"\"\"\n",
    "    Core logic: Only retain texts with a difficulty level lower than original_cefr.    \n",
    "    \"\"\"\n",
    "    original_lvl = row['original_cefr']\n",
    "    \n",
    "    # not in level_map than skip\n",
    "    if original_lvl not in level_map:\n",
    "        return row\n",
    "    \n",
    "    # original level score\n",
    "    orig_idx = level_map[original_lvl]\n",
    "    \n",
    "    # text_A1, text_A2...\n",
    "    for lvl in cefr_levels:\n",
    "        target_idx = level_map[lvl]\n",
    "        col_name = f'text_{lvl}'\n",
    "        \n",
    "        # target >= original level, delte (Noneï¼‰\n",
    "        if target_idx >= orig_idx:\n",
    "            row[col_name] = None\n",
    "            \n",
    "    return row\n",
    "\n",
    "print(\"cleanning now...\")\n",
    "df_clean = df.apply(filter_simplification, axis=1)\n",
    "\n",
    "# delete all A1 easiest level: no use\n",
    "cols_to_check = [f'text_{lvl}' for lvl in cefr_levels]\n",
    "df_final = df_clean.dropna(subset=cols_to_check, how='all')\n",
    "\n",
    "#save results\n",
    "output_file = \"cambridge_simplified levels_only.csv\"\n",
    "df_final.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"âœ… mission accomplishedï¼\")\n",
    "print(f\"original row: {len(df)}\")\n",
    "print(f\"new row: {len(df_final)}\")\n",
    "print(f\"save as: {output_file}\")\n",
    "\n",
    "# small check\n",
    "print(\"\\n preview level B2 (A1, A2, B1):\")\n",
    "b2_example = df_final[df_final['original_cefr'] == 'B2'].head(1)\n",
    "if not b2_example.empty:\n",
    "    cols = ['original_cefr', 'text_A1', 'text_A2', 'text_B1', 'text_B2', 'text_C1']\n",
    "    print(b2_example[cols].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52f8ca5e-d83a-46e9-925a-4fa4ea065c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.13/site-packages (2.8.0)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.13/site-packages (4.57.3)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.13/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests->transformers) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cfe8cb-aff5-425b-ae5a-00455e549531",
   "metadata": {},
   "source": [
    "# Evaluation: Clean those who do not satisfied with our Standard\n",
    "Our device: Macbookpro m4pro 14CPU+20GPU core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74969765-2da5-46e3-b73f-67f294eb98cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ›¡ï¸ Running on device: cpu (Stable Mode)\n",
      "Loading model: AbdulSami/bert-base-cased-cefr...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ========================================================\n",
    "# 1. ç»ˆæç¨³å®šé…ç½® (Python 3.10 + CPU + Verified Model)\n",
    "# ========================================================\n",
    "\n",
    "# ç¦ç”¨å¹¶è¡Œï¼Œé˜²æ­¢æ­»é”\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# å¼ºåˆ¶ CPU (åœ¨ Python 3.10 ä¸‹éå¸¸ç¨³å®š)\n",
    "DEVICE = \"cpu\"\n",
    "print(f\"ğŸ›¡ï¸ Running on device: {DEVICE} (Stable Mode)\")\n",
    "\n",
    "# âœ… è¿™æ˜¯ä¸€ä¸ªçœŸå®å­˜åœ¨ã€æ¶æ„æˆç†Ÿçš„ CEFR æ¨¡å‹\n",
    "CEFR_MODEL_NAME = \"AbdulSami/bert-base-cased-cefr\"\n",
    "\n",
    "# ========================================================\n",
    "# 2. æ ¸å¿ƒé€»è¾‘\n",
    "# ========================================================\n",
    "\n",
    "def load_model():\n",
    "    print(f\"Loading model: {CEFR_MODEL_NAME}...\")\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(CEFR_MODEL_NAME)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(CEFR_MODEL_NAME)\n",
    "        model.to(DEVICE)\n",
    "        model.eval()\n",
    "        print(\"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼(Python 3.10 ç¯å¢ƒéªŒè¯é€šè¿‡)\")\n",
    "        return tokenizer, model\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def predict_batch(texts, tok, model, batch_size=16):\n",
    "    labels = []\n",
    "    \n",
    "    # è‡ªåŠ¨è¯»å–æ¨¡å‹çš„æ ‡ç­¾æ˜ å°„ {0: 'A1', 1: 'A2'...}\n",
    "    id2label = model.config.id2label\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for start in tqdm(range(0, len(texts), batch_size), desc=\"Evaluating\"):\n",
    "            batch = texts[start:start + batch_size]\n",
    "            if not batch: continue\n",
    "\n",
    "            enc = tok(\n",
    "                batch,\n",
    "                truncation=True,\n",
    "                padding=True,\n",
    "                max_length=512,\n",
    "                return_tensors=\"pt\",\n",
    "            ).to(DEVICE)\n",
    "\n",
    "            logits = model(**enc).logits\n",
    "            idxs = logits.argmax(dim=-1)\n",
    "\n",
    "            for i in range(len(batch)):\n",
    "                idx = int(idxs[i].item())\n",
    "                # ç›´æ¥ä»æ¨¡å‹é…ç½®é‡Œæ‹¿æ ‡ç­¾ï¼Œä¸å†æ€•é¡ºåºæé”™\n",
    "                label = id2label.get(idx, \"Unknown\")\n",
    "                labels.append(label)\n",
    "                \n",
    "    return labels\n",
    "\n",
    "# ========================================================\n",
    "# 3. æ‰§è¡Œæ¸…æ´—\n",
    "# ========================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tokenizer, model = load_model()\n",
    "\n",
    "    if model:\n",
    "        # ğŸ”´ è®°å¾—æŠŠè¿™é‡Œæ”¹æˆä½ å…·ä½“è¦æ¸…æ´—çš„æ–‡ä»¶å\n",
    "        input_file = \"cambridge_simplified_only.csv\"\n",
    "        \n",
    "        if os.path.exists(input_file):\n",
    "            df = pd.read_csv(input_file)\n",
    "            print(f\"åŸå§‹æ•°æ®: {len(df)} è¡Œ\")\n",
    "            \n",
    "            # æ”¶é›†ä»»åŠ¡\n",
    "            tasks = []\n",
    "            target_cols = [f\"text_{lvl}\" for lvl in [\"A1\", \"A2\", \"B1\", \"B2\", \"C1\", \"C2\"]]\n",
    "            \n",
    "            for idx, row in df.iterrows():\n",
    "                for col in target_cols:\n",
    "                    if col in df.columns and pd.notna(row[col]):\n",
    "                        tasks.append((idx, col, str(row[col])))\n",
    "\n",
    "            if tasks:\n",
    "                print(f\"å¼€å§‹éªŒè¯ {len(tasks)} ä¸ªç‰‡æ®µ...\")\n",
    "                all_texts = [t[2] for t in tasks]\n",
    "                preds = predict_batch(all_texts, tokenizer, model, batch_size=16)\n",
    "\n",
    "                kept, dropped = 0, 0\n",
    "                for i, (row_idx, col, text) in enumerate(tasks):\n",
    "                    target_lvl = col.split(\"_\")[1] # text_A1 -> A1\n",
    "                    pred_lvl = preds[i]\n",
    "                    \n",
    "                    # ç®€å•æ¸…æ´—ä¸€ä¸‹æ ‡ç­¾ (æœ‰äº›æ¨¡å‹è¾“å‡ºå¸¦æœ‰ç©ºæ ¼)\n",
    "                    if pred_lvl.strip() == target_lvl:\n",
    "                        kept += 1\n",
    "                    else:\n",
    "                        df.at[row_idx, col] = None\n",
    "                        dropped += 1\n",
    "                \n",
    "                # ä¿å­˜\n",
    "                df.dropna(subset=target_cols, how='all').to_csv(\"cambridge_verified_final.csv\", index=False)\n",
    "                print(f\"\\nğŸ‰ æˆåŠŸï¼ä¿ç•™: {kept} | åˆ é™¤: {dropped}\")\n",
    "                print(\"ç»“æœå·²ä¿å­˜è‡³: cambridge_verified_final.csv\")\n",
    "            else:\n",
    "                print(\"æ²¡æœ‰æ‰¾åˆ°éœ€è¦éªŒè¯çš„æ•°æ®åˆ—ï¼\")\n",
    "        else:\n",
    "            print(f\"æ‰¾ä¸åˆ°æ–‡ä»¶: {input_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dd4f1b-e1ff-4d5a-8b7e-7578fc8a9ef4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
